# 🤖 AI-SignSpeak

### 🧠 Real-Time Sign Language to Speech Converter using Convolutional Neural Networks (CNNs)

---

## 🌍 Overview

**AI-SignSpeak** is an intelligent system that bridges the communication gap between people with speech or hearing impairments and the rest of the world.  
It captures **hand gestures** via a webcam, recognizes them using a **CNN-based model**, and converts the recognized gesture into **spoken words** using **text-to-speech**.

This project is part of the **Neural Networks** module at **Euromed University of Fes (UEMF)** and was developed by **Ibtissam El Hichou** 🎓.

---

## 🚀 Features

✅ **Real-time gesture detection** with a live webcam feed  
✅ **Hand tracking** powered by [MediaPipe](https://developers.google.com/mediapipe)  
✅ **Gesture classification** using a CNN model  
✅ **Speech synthesis** using [pyttsx3](https://pypi.org/project/pyttsx3/)  
✅ **Lightweight, beginner-friendly, and runs locally**

---

## 🧩 Tech Stack

| Component | Library / Tool |
|------------|----------------|
| 🖐️ Hand Detection | MediaPipe |
| 🧠 Model Training | TensorFlow / Keras |
| 📷 Camera Input | OpenCV |
| 🔊 Speech Output | pyttsx3 |
| 🧮 Data Handling | NumPy, Matplotlib |

---

## 🛠️ Installation & Setup

1. **Clone this repository**
   ```bash
   git clone https://github.com/betty4567898/AI-SignSpeak.git
   cd AI-SignSpeak
